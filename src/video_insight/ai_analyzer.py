import os
import time
import base64
import json
import requests
import logging
from pathlib import Path
from typing import List, Dict, Optional, Any, Tuple

from openpyxl import Workbook
from openpyxl.drawing.image import Image as ExcelImage
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter

from .config import config

logger = logging.getLogger("AIAnalyzer")

class FeishuClient:
    """é£ä¹¦ Wiki/å¤šç»´è¡¨æ ¼ æ•°æ®è·å–å®¢æˆ·ç«¯ã€‚"""
    def __init__(self, app_id: str, app_secret: str):
        self.app_id = app_id
        self.app_secret = app_secret
        self.token = None
        self.headers = None

    def _ensure_token(self):
        """ç¡®ä¿å­˜åœ¨æœ‰æ•ˆçš„ tenant_access_tokenã€‚"""
        if not self.token:
            url = f"{config.FEISHU_DOMAIN}/open-apis/auth/v3/tenant_access_token/internal"
            payload = {"app_id": self.app_id, "app_secret": self.app_secret}
            try:
                res = requests.post(url, json=payload, timeout=10)
                res.raise_for_status()
                self.token = res.json().get("tenant_access_token")
                self.headers = {
                    "Authorization": f"Bearer {self.token}",
                    "Content-Type": "application/json; charset=utf-8"
                }
            except Exception as e:
                logger.error(f"è·å– Token å¤±è´¥: {e}")
                raise

    def get_app_token_from_wiki(self, wiki_token: str) -> Optional[str]:
        """è§£æ Wiki Token ä¸ºå¤šç»´è¡¨æ ¼ App Tokenã€‚"""
        self._ensure_token()
        url = f"{config.FEISHU_DOMAIN}/open-apis/wiki/v2/space_node/get"
        params = {"token": wiki_token}
        
        try:
            res = requests.get(url, headers=self.headers, params=params, timeout=10)
            res.raise_for_status()
            data = res.json().get("data", {})
            node = data.get("node", {})
            obj_type = node.get("obj_type")
            obj_token = node.get("obj_token")
            
            if obj_type != "bitable":
                logger.warning(f"Wiki èŠ‚ç‚¹ç±»å‹æ˜¯ '{obj_type}', é¢„æœŸä¸º 'bitable'ã€‚")
            
            return obj_token
        except Exception as e:
                logger.error(f"è§£æ Wiki èŠ‚ç‚¹å¤±è´¥: {e}")
                raise

    def get_all_records(self, app_token: str, table_id: str, view_id: str = None) -> List[Dict]:
        """è·å–å¤šç»´è¡¨æ ¼æ‰€æœ‰è®°å½•ã€‚"""
        self._ensure_token()
        all_records = []
        page_token = ""
        has_more = True
        
        logger.info("æ­£åœ¨ä»é£ä¹¦å¤šç»´è¡¨æ ¼è·å–æ•°æ®...")
        while has_more:
            url = f"{config.FEISHU_DOMAIN}/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records"
            params = {"page_size": 100, "page_token": page_token}
            if view_id:
                params["view_id"] = view_id
                
            try:
                res = requests.get(url, headers=self.headers, params=params, timeout=20)
                res.raise_for_status()
                data = res.json().get("data", {})
                
                items = data.get("items", [])
                all_records.extend(items)
                
                has_more = data.get("has_more", False)
                page_token = data.get("page_token", "")
            except Exception as e:
                logger.error(f"è·å–è®°å½•å¤±è´¥: {e}")
                break
        
        logger.info(f"æˆåŠŸè·å– {len(all_records)} æ¡è®°å½•ã€‚")
        return all_records

class AdsAnalyzer:
    def __init__(self, output_dir: Path = None, assets_dir: Path = None):
        self.output_dir = output_dir or config.RESULT_DIR
        self.assets_dir = assets_dir or config.OUTPUT_DIR
        self.api_key = config.DASHSCOPE_API_KEY
        self.feishu_client = FeishuClient(config.FEISHU_APP_ID, config.FEISHU_APP_SECRET)
        
        if not self.api_key:
            logger.warning("ç¯å¢ƒå˜é‡ä¸­æœªæ‰¾åˆ° DASHSCOPE_API_KEYã€‚")

        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾åƒç¼–ç ä¸º base64ã€‚"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def _get_system_prompt(self) -> str:
        return """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„èµ„æ·±çŸ­è§†é¢‘å¹¿å‘Šåˆ†æå¸ˆã€‚è¯·åŸºäºæˆ‘æä¾›çš„ã€Œè§†é¢‘å®«æ ¼å›¾ã€ã€ã€Œè§†é¢‘æ–‡æ¡ˆã€ï¼Œè¿›è¡Œæ·±åº¦åˆ†æã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹åˆ†æç»´åº¦å’Œçº¦æŸæ¡ä»¶ï¼š

1. **å—ä¼—äººç¾¤ (Audience)**ï¼š
   - å¿…é¡»åŸºäºè§†é¢‘å†…å®¹ç²¾å‡†å®šä½ï¼Œå¹¶æ˜ å°„åˆ°ä»¥ä¸‹æ ‡å‡†åˆ†ç±»è¯ä¸­ï¼ˆä¼˜å…ˆé€‰æ‹©æœ€å…·ä½“çš„ä¸€ä¸ªï¼‰ï¼š
   - åˆ†ç±»è¯åº“ï¼š[å¹´è½»å¥³æ€§, å¹´è½»äºº, èŒåœºç™½é¢†, é€šç”¨, å¥èº«äººç¾¤, æƒ…ä¾£, è€äºº, å„¿ç«¥, å®¶é•¿, å­¦ç”Ÿ, å®å¦ˆ]
   - è§„åˆ™ï¼šå®šä½åˆ°å…·ä½“äººç¾¤ï¼Œä¾‹å¦‚å¦‚æœåˆ†æç»“æœæ˜¯20-30å²å¥³æ€§ï¼Œå¿…é¡»è¾“å‡ºâ€œå¹´è½»å¥³æ€§â€ï¼Œè€Œä¸æ˜¯â€œå¹´è½»äººâ€ã€‚

2. **æ ¸å¿ƒåŠŸèƒ½ (Function)**ï¼š
   - è¯†åˆ«è§†é¢‘æ¨å¹¿çš„æ ¸å¿ƒå–ç‚¹ï¼Œå¹¶æ˜ å°„åˆ°ä»¥ä¸‹æ ‡å‡†åˆ†ç±»è¯ï¼ˆè‹¥æ¶‰åŠå¤šä¸ªï¼Œä¼˜å…ˆé€‰æ‹©æœ€æ ¸å¿ƒçš„ä¸€ä¸ªï¼Œä»…åœ¨æ— æ³•åŒºåˆ†ä¸»æ¬¡æ—¶é€‰æ‹©â€œç»¼åˆå–ç‚¹â€ï¼‰ï¼š
   - åˆ†ç±»è¯åº“ï¼š[æœˆæš–æš–, é¥®é£Ÿå¥åº·å°åŠ©æ‰‹, å¥åº·å°ç›®æ ‡, å¿ƒç†å¥åº·è‡ªæµ‹, æµæ„Ÿå¥åº·æ”»ç•¥, è¯ç®¡å®¶, å¥åº·æ¡£æ¡ˆ, é—®ç­”, å£è…”å°åŠ©ç†, ä¸­åŒ»å…»ç”Ÿ, ç»¼åˆå–ç‚¹, AIè§£è¯»æ™ºèƒ½æŠ¥å‘Š]

3. **æ ¸å¿ƒç—›ç‚¹ (Pain Point)**ï¼š
   - ç»“åˆæ–‡æ¡ˆå’Œç”»é¢ï¼Œæ€»ç»“ç”¨æˆ·é¢ä¸´çš„å…·ä½“é—®é¢˜ã€‚
   - çº¦æŸï¼šå¿…é¡»ç¼©çŸ­æˆç®€å•çš„ä¸€å¥è¯ï¼ˆ15å­—ä»¥å†…ï¼‰ã€‚
   - ç¤ºä¾‹ï¼šâ€œå¿˜è®°è¯å“æ¥æºâ€ã€â€œä¸çŸ¥é“è¯å“ç¦å¿Œâ€ã€â€œå‡å°‘ç„¦è™‘â€ã€â€œç—›ç»ç¼“è§£â€ã€‚

4. **åº”ç”¨åœºæ™¯ (Scenario)**ï¼š
   - ä»…é™ä»ä»¥ä¸‹ä¸‰ä¸ªé€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š[ç”Ÿæ´»åœºæ™¯, å·¥ä½œåœºæ™¯, ç‰¹æ®Šåœºæ™¯]
   - è§„åˆ™ï¼šç‰¹æ®Šåœºæ™¯æƒé‡æœ€ä½ï¼Œä»…åœ¨æ— æ³•å½’ç±»ä¸ºç”Ÿæ´»æˆ–å·¥ä½œæ—¶ä½¿ç”¨ã€‚

5. **æ¦‚è¿° (Overview)**ï¼š
   - ç®€è¦æè¿°è§†é¢‘çš„ä¸»è¦å†…å®¹ã€å‰§æƒ…èµ°å‘æˆ–å±•ç°å½¢å¼ã€‚
   - **ä¸¥ç¦**ä½¿ç”¨â€œè§†é¢‘é€šè¿‡...â€ã€â€œè¯¥è§†é¢‘å±•ç¤ºäº†...â€ç­‰å¼•å¯¼è¯­ã€‚
   - ç›´æ¥é™ˆè¿°ç”»é¢å†…å®¹æˆ–å‰§æƒ…ã€‚

6. **æ·±åº¦åˆ†æ (Analysis)**ï¼š
   - ç»“åˆæä¾›çš„æŠ•æ”¾æ•°æ®ï¼ˆå±•ç°ã€ç‚¹å‡»ã€æ¶ˆè€—ã€æ¿€æ´»ã€ç‚¹å‡»ç‡CTRã€è½¬æ¢ç‡CVRï¼‰è¿›è¡Œç»¼åˆè¯„åˆ¤ã€‚
   - **ä¸¥ç¦**ä½¿ç”¨â€œæ ¹æ®æ•°æ®åˆ†æ...â€ã€â€œä»æ•°æ®æ¥çœ‹...â€ç­‰åºŸè¯ã€‚ç›´æ¥ç»™å‡ºç»“è®ºã€‚
   - **ç‰¹åˆ«æ³¨æ„**ï¼šè¯·æ˜¾è‘—æå‡ã€Œæ¶ˆè€—ã€æ•°æ®çš„åˆ†ææƒé‡ã€‚æ¶ˆè€—ä»£è¡¨äº†å…¬å¸çš„å®é™…æŠ•å…¥å’Œæ½œåœ¨æ”¶ç›Šè§„æ¨¡ã€‚
     - å¯¹äº**é«˜æ¶ˆè€—**è§†é¢‘ï¼šéœ€ä¸¥æ ¼å®¡è§†å…¶è½¬åŒ–ç‡å’Œç‚¹å‡»ç‡ï¼Œåˆ†æä¸ºä½•èƒ½è·‘å‡ºé«˜æ¶ˆè€—ï¼ˆç´ æå“ªé‡Œå¸å¼•äººï¼Ÿï¼‰ä»¥åŠæ˜¯å¦å­˜åœ¨â€œé«˜è€—ä½æ•ˆâ€çš„æµªè´¹é£é™©ã€‚
     - å¯¹äº**ä½æ¶ˆè€—**è§†é¢‘ï¼šåˆ†ææœªèƒ½è·‘é‡çš„åŸå› ï¼ˆæ˜¯å°é¢ä¸å¸å¼•äººå¯¼è‡´ç‚¹å‡»ç‡ä½ï¼Œè¿˜æ˜¯å†…å®¹å¹³åº¸ï¼‰ã€‚
   - ç»¼åˆåˆ¤æ–­è§†é¢‘çš„ä¼˜åŠ£ï¼Œå¹¶ç»™å‡ºä¼˜åŒ–æ–¹å‘ã€‚

**è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š
è¯·ç›´æ¥è¿”å›æ ‡å‡†çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«Markdownæ ‡è®°æˆ–å…¶ä»–åºŸè¯ï¼š
{
    "äººç¾¤": "å¹´è½»å¥³æ€§",
    "åŠŸèƒ½": "æœˆæš–æš–",
    "ç—›ç‚¹": "ç—›ç»ç¼“è§£",
    "åœºæ™¯": "ç”Ÿæ´»åœºæ™¯",
    "æ¦‚è¿°": "å¹´è½»å¥³æ€§åœ¨åŠå…¬å®¤æ‚ç€è‚šå­ï¼Œè¡¨æƒ…ç—›è‹¦ï¼Œéšåæ‹¿å‡ºæœˆæš–æš–äº§å“ä½¿ç”¨ï¼Œè¡¨æƒ…èˆ’ç¼“ã€‚",
    "åˆ†æ": "ç‚¹å‡»ç‡è¾ƒé«˜ï¼ˆX%ï¼‰ï¼Œå°é¢ç—›ç‚¹ç›´å‡»äººå¿ƒã€‚æ¶ˆè€—è¾ƒé«˜ä½†è½¬åŒ–ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–è½åœ°é¡µå¼•å¯¼ã€‚"
}"""

    def _call_qwen_vl(self, image_path: str, text_content: str, performance_data: Dict) -> Optional[Dict]:
        """è°ƒç”¨ Qwen-VL-Plus APIã€‚"""
        url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        perf_str = "\n".join([f"{k}: {v}" for k, v in performance_data.items()])
        
        user_content = [
            {"image": f"data:image/jpeg;base64,{self._encode_image(image_path)}"},
            {"text": f"ã€è§†é¢‘æ–‡æ¡ˆã€‘ï¼š\n{text_content}\n\nã€æŠ•æ”¾æ•°æ®ã€‘ï¼š\n{perf_str}\n\nè¯·æ ¹æ®ä¸Šè¿°ç´ æå’Œæ•°æ®è¿›è¡Œåˆ†æã€‚"}
        ]

        payload = {
            "model": "qwen-vl-plus-2025-08-15",
            "input": {
                "messages": [
                    {"role": "system", "content": [{"text": self._get_system_prompt()}]},
                    {"role": "user", "content": user_content}
                ]
            },
            "parameters": {
                "result_format": "message"
            }
        }

        for attempt in range(3):
            try:
                response = requests.post(url, headers=headers, json=payload, timeout=60)
                response.raise_for_status()
                result = response.json()
                
                if "output" in result and "choices" in result["output"]:
                    content = result["output"]["choices"][0]["message"]["content"][0]["text"]
                    content = content.replace("```json", "").replace("```", "").strip()
                    return json.loads(content)
                else:
                    logger.error(f"æ„å¤–å“åº”: {result}")
            
            except Exception as e:
                logger.error(f"ç¬¬ {attempt+1}/3 æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < 2:
                    time.sleep(2)
        
        return None

    def _find_assets(self, material_name: str) -> Tuple[Optional[str], Optional[str]]:
        """åœ¨èµ„æºç›®å½•ä¸­æŸ¥æ‰¾æ‹¼å›¾å’Œ ASR æ–‡æ¡ˆã€‚"""
        # èµ„æºç›®å½•é€šå¸¸æ˜¯å¤„ç†åçš„ç»“æœç›®å½•: assets_dir / material_name / (material_name_sheet.jpg & material_name_asr.txt)
        material_dir = self.assets_dir / material_name
        
        sheet_path = material_dir / f"{material_name}_sheet.jpg"
        text_path = material_dir / f"{material_name}_asr.txt"
        
        if sheet_path.exists() and text_path.exists():
            return str(sheet_path), str(text_path)
            
        return None, None

    def _fetch_feishu_data(self, app_token: str = None, table_id: str = None) -> List[Dict]:
        """è·å–å¹¶æ ‡å‡†åŒ–é£ä¹¦æ•°æ®ã€‚"""
        target_app_token = app_token
        target_table_id = table_id

        if not target_app_token:
            logger.info("æ­£åœ¨ä» Wiki Token è§£æ App Token...")
            target_app_token = self.feishu_client.get_app_token_from_wiki(config.WIKI_TOKEN)
        
        if not target_app_token:
            logger.error("è·å– App Token å¤±è´¥")
            return []
            
        logger.info(f"App Token: {target_app_token}")
        # å¦‚æœæœªæä¾› table_idï¼Œä½¿ç”¨é…ç½®æˆ–è·å–ç¬¬ä¸€ä¸ªè¡¨
        if not target_table_id:
             target_table_id = config.SOURCE_TABLE_ID
             
        records = self.feishu_client.get_all_records(target_app_token, target_table_id)
        
        normalized_data = []
        for r in records:
            fields = r.get("fields", {})
            
            # æ ‡å‡†åŒ–é“¾æ¥
            url_field = fields.get("è§†é¢‘é“¾æ¥")
            url = ""
            if isinstance(url_field, str):
                url = url_field
            elif isinstance(url_field, list) and len(url_field) > 0:
                url = url_field[0].get("url", "") or url_field[0].get("link", "")
            elif isinstance(url_field, dict):
                url = url_field.get("url", "") or url_field.get("link", "")
                
            # æ ‡å‡†åŒ–æ¥æº
            source_field = fields.get("æ¥æº", "")
            source = ""
            if isinstance(source_field, str):
                source = source_field
            elif isinstance(source_field, list) and len(source_field) > 0:
                item_0 = source_field[0]
                if isinstance(item_0, dict):
                    source = item_0.get("text", "") or item_0.get("name", "")
                else:
                    source = str(item_0)
            elif isinstance(source_field, dict):
                source = source_field.get("text", "") or source_field.get("name", "")

            item = {
                "ç´ æåç§°": fields.get("ç´ æåç§°", ""),
                "è§†é¢‘é“¾æ¥": url,
                "å±•ç°": fields.get("å±•ç°", 0),
                "ç‚¹å‡»": fields.get("ç‚¹å‡»", 0),
                "æ¶ˆè€—": fields.get("æ¶ˆè€—", 0),
                "æ¿€æ´»äººæ•°": fields.get("æ¿€æ´»äººæ•°", 0),
                "æ¥æº": source
            }
            normalized_data.append(item)
            
        return normalized_data

    def process(self, source_app_token: str = None, source_table_id: str = None, progress_callback=None) -> List[Dict]:
        """æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼šè¯»å–æºè¡¨ï¼Œåˆ†æè§†é¢‘ï¼Œè¿”å›ç»“æœåˆ—è¡¨ã€‚"""
        # 1. ç¡®å®šç›®æ ‡è¡¨
        target_app_token = source_app_token
        if not target_app_token:
            logger.info("æ­£åœ¨ä» Wiki Token è§£æ App Token...")
            target_app_token = self.feishu_client.get_app_token_from_wiki(config.SOURCE_WIKI_TOKEN)
            
        if not target_app_token:
            logger.error("è·å– App Token å¤±è´¥")
            return []
            
        logger.info(f"App Token: {target_app_token}")
        target_table_id = source_table_id or config.SOURCE_TABLE_ID

        data = self._fetch_feishu_data(target_app_token, target_table_id)
        
        results = []
        total_rows = len(data)
        logger.info(f"å‘ç° {total_rows} è¡Œå¾…å¤„ç†æ•°æ®ã€‚")
        
        success_count = 0
        skip_count = 0
        
        # å®šä¹‰è¿›åº¦é€šçŸ¥æ­¥é•¿ (ä¾‹å¦‚æ€»æ•°çš„ 20%ï¼Œæˆ–è€…è‡³å°‘æ¯ 10 æ¡ä¸€æ¬¡)
        report_step = max(1, total_rows // 5) if total_rows > 10 else 1

        for index, row in enumerate(data):
            material_name = str(row.get('ç´ æåç§°', ''))
            if material_name.lower().endswith('.mp4'):
                material_name = material_name[:-4]
            material_name = material_name.strip()

            if not material_name:
                skip_count += 1
                continue
            
            if progress_callback:
                progress_callback(f"ğŸ¤– [3/4] æ­£åœ¨åˆ†æ ({index+1}/{total_rows}): {material_name}")
                
            logger.info(f"æ­£åœ¨å¤„ç†: {material_name}")
            
            # æŸ¥æ‰¾ç´ æ
            sheet_path, text_path = self._find_assets(material_name)
            if not sheet_path or not text_path:
                logger.warning(f"{material_name}: æœªæ‰¾åˆ°æœ¬åœ°ç´ æ (è·³è¿‡åˆ†æ)")
                skip_count += 1
                # å³ä½¿æ˜¯é™é»˜æ¨¡å¼ï¼Œè·³è¿‡çš„ä¿¡æ¯ä¹Ÿå»ºè®®æ˜¾ç¤ºï¼Œæ–¹ä¾¿æ’æŸ¥
                if progress_callback:
                    progress_callback(f"âš ï¸ {material_name}: æœªæ‰¾åˆ°æœ¬åœ°ç´ æ (è·³è¿‡åˆ†æ)")
                continue

            # è¯»å–æ–‡æ¡ˆ
            try:
                with open(text_path, "r", encoding="utf-8") as f:
                    text_content = f.read()
            except Exception as e:
                logger.error(f"è¯»å–æ–‡æ¡ˆå¤±è´¥: {e}")
                skip_count += 1
                continue

            # æå–æŠ•æ”¾æ•°æ®
            perf_data = {
                "å±•ç°": row.get("å±•ç°", 0),
                "ç‚¹å‡»": row.get("ç‚¹å‡»", 0),
                "æ¶ˆè€—": row.get("æ¶ˆè€—", 0),
                "æ¿€æ´»äººæ•°": row.get("æ¿€æ´»äººæ•°", 0),
                "æ¥æº": row.get("æ¥æº", "")
            }

            # è°ƒç”¨ AI
            analysis_json = self._call_qwen_vl(sheet_path, text_content, perf_data)
            if analysis_json:
                # åˆå¹¶ç»“æœ
                res_item = {**row, **analysis_json}
                
                # æ˜¾å¼æ·»åŠ ç¼©ç•¥å›¾è·¯å¾„ï¼Œä»¥ä¾¿ Syncer å¯ä»¥ä¸Šä¼ 
                if sheet_path and os.path.exists(sheet_path):
                    res_item["ç¼©ç•¥å›¾"] = sheet_path
                
                results.append(res_item)
                success_count += 1
                
                # è¿›åº¦é€šçŸ¥é€»è¾‘ï¼š
                # 1. å¦‚æœæ•°æ®é‡å° (<10)ï¼Œé€æ¡é€šçŸ¥
                # 2. å¦‚æœæ•°æ®é‡å¤§ï¼ŒæŒ‰æ­¥é•¿é€šçŸ¥
                if progress_callback:
                    if total_rows <= 10:
                        # é€æ¡é€šçŸ¥ä¸éœ€è¦æ˜¾ç¤ºå…·ä½“ JSONï¼Œåªæ˜¾ç¤ºæˆåŠŸçŠ¶æ€
                        pass 
                    elif (success_count % report_step == 0) or (index + 1 == total_rows):
                        progress_callback(f"ğŸ“Š AI åˆ†æè¿›åº¦: {index+1}/{total_rows} (å·²å®Œæˆ {success_count} æ¡)")
            else:
                skip_count += 1
                if progress_callback:
                    progress_callback(f"âŒ {material_name}: AI åˆ†æå¤±è´¥")

        if progress_callback:
            progress_callback(f"âœ… AI åˆ†æå…¨éƒ¨å®Œæˆï¼Œç”Ÿæˆ {len(results)} æ¡ç»“æœã€‚")
            
        return results

    # ä¿ç•™æ—§æ–¹æ³•ä»¥å…¼å®¹ CLI (å¦‚æœéœ€è¦)ï¼Œä½†åœ¨æ–°ç®¡çº¿ä¸­æœªä½¿ç”¨
    def _save_excel(self, results: List[Dict]):
        pass

if __name__ == "__main__":
    logger.info("ğŸš€ å¼€å§‹å¹¿å‘Šåˆ†æ...")
    analyzer = AdsAnalyzer()
    results = analyzer.process()
    # print(json.dumps(results, ensure_ascii=False, indent=2))
