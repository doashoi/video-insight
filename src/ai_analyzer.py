import os
import time
import base64
import json
import requests
from pathlib import Path
from typing import List, Dict, Optional, Any, Tuple

from openpyxl import Workbook
from openpyxl.drawing.image import Image as ExcelImage
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter

from feishu_syncer import FeishuSyncer

from config import config


class FeishuClient:
    """é£ä¹¦ Wiki/å¤šç»´è¡¨æ ¼ æ•°æ®è·å–å®¢æˆ·ç«¯ã€‚"""

    def __init__(self, app_id: str, app_secret: str):
        self.app_id = app_id
        self.app_secret = app_secret
        self.token = None
        self.headers = None

    def _ensure_token(self):
        """ç¡®ä¿å­˜åœ¨æœ‰æ•ˆçš„ tenant_access_tokenã€‚"""
        if not self.token:
            url = (
                f"{config.FEISHU_DOMAIN}/open-apis/auth/v3/tenant_access_token/internal"
            )
            payload = {"app_id": self.app_id, "app_secret": self.app_secret}
            try:
                res = requests.post(url, json=payload, timeout=10)
                res.raise_for_status()
                self.token = res.json().get("tenant_access_token")
                self.headers = {
                    "Authorization": f"Bearer {self.token}",
                    "Content-Type": "application/json; charset=utf-8",
                }
            except Exception as e:
                print(f"[Feishu Error] è·å– Token å¤±è´¥: {e}")
                raise

    def get_app_token_from_wiki(self, wiki_token: str) -> Optional[str]:
        """è§£æ Wiki Token ä¸ºå¤šç»´è¡¨æ ¼ App Tokenã€‚"""
        self._ensure_token()
        url = f"{config.FEISHU_DOMAIN}/open-apis/wiki/v2/spaces/get_node"
        params = {"token": wiki_token}

        try:
            res = requests.get(url, headers=self.headers, params=params, timeout=10)
            res.raise_for_status()
            data = res.json().get("data", {})
            node = data.get("node", {})
            obj_type = node.get("obj_type")
            obj_token = node.get("obj_token")

            if obj_type != "bitable":
                print(f"[Warning] Wiki èŠ‚ç‚¹ç±»å‹æ˜¯ '{obj_type}', é¢„æœŸä¸º 'bitable'ã€‚")

            return obj_token
        except Exception as e:
            print(f"[Feishu Error] è§£æ Wiki èŠ‚ç‚¹å¤±è´¥: {e}")
            raise

    def get_all_records(
        self, app_token: str, table_id: str, view_id: str = None
    ) -> List[Dict]:
        """è·å–å¤šç»´è¡¨æ ¼æ‰€æœ‰è®°å½•ã€‚"""
        self._ensure_token()
        all_records = []
        page_token = ""
        has_more = True

        print("ğŸ” æ­£åœ¨ä»é£ä¹¦å¤šç»´è¡¨æ ¼è·å–æ•°æ®...")
        while has_more:
            url = f"{config.FEISHU_DOMAIN}/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records"
            params = {"page_size": 100, "page_token": page_token}
            if view_id:
                params["view_id"] = view_id

            try:
                res = requests.get(url, headers=self.headers, params=params, timeout=20)
                res.raise_for_status()
                data = res.json().get("data", {})

                items = data.get("items", [])
                all_records.extend(items)

                has_more = data.get("has_more", False)
                page_token = data.get("page_token", "")
            except Exception as e:
                print(f"[Feishu Error] è·å–è®°å½•å¤±è´¥: {e}")
                break

        print(f"âœ… æˆåŠŸè·å– {len(all_records)} æ¡è®°å½•ã€‚")
        return all_records


class AdsAnalyzer:
    def __init__(self):
        self.output_dir = config.RESULT_DIR
        self.assets_dir = config.OUTPUT_DIR
        self.api_key = config.DASHSCOPE_API_KEY
        self.feishu_client = FeishuClient(
            config.FEISHU_APP_ID, config.FEISHU_APP_SECRET
        )

        if not self.api_key:
            print("[Warning] ç¯å¢ƒå˜é‡ä¸­æœªæ‰¾åˆ° DASHSCOPE_API_KEYã€‚")

        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _encode_image(self, image_path: str) -> str:
        """å°†å›¾åƒç¼–ç ä¸º base64ã€‚"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")

    def _get_system_prompt(self) -> str:
        return """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„èµ„æ·±çŸ­è§†é¢‘å¹¿å‘Šåˆ†æå¸ˆã€‚è¯·åŸºäºæˆ‘æä¾›çš„ã€Œè§†é¢‘å®«æ ¼å›¾ã€ã€ã€Œè§†é¢‘æ–‡æ¡ˆã€ï¼Œè¿›è¡Œæ·±åº¦åˆ†æã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹åˆ†æç»´åº¦å’Œçº¦æŸæ¡ä»¶ï¼š

1. **å—ä¼—äººç¾¤ (Audience)**ï¼š
   - å¿…é¡»åŸºäºè§†é¢‘å†…å®¹ç²¾å‡†å®šä½ï¼Œå¹¶æ˜ å°„åˆ°ä»¥ä¸‹æ ‡å‡†åˆ†ç±»è¯ä¸­ï¼ˆä¼˜å…ˆé€‰æ‹©æœ€å…·ä½“çš„ä¸€ä¸ªï¼‰ï¼š
   - åˆ†ç±»è¯åº“ï¼š[å¹´è½»å¥³æ€§, å¹´è½»äºº, èŒåœºç™½é¢†, é€šç”¨, å¥èº«äººç¾¤, æƒ…ä¾£, è€äºº, å„¿ç«¥, å®¶é•¿, å­¦ç”Ÿ, å®å¦ˆ]
   - è§„åˆ™ï¼šå®šä½åˆ°å…·ä½“äººç¾¤ï¼Œä¾‹å¦‚å¦‚æœåˆ†æç»“æœæ˜¯20-30å²å¥³æ€§ï¼Œå¿…é¡»è¾“å‡ºâ€œå¹´è½»å¥³æ€§â€ï¼Œè€Œä¸æ˜¯â€œå¹´è½»äººâ€ã€‚

2. **æ ¸å¿ƒåŠŸèƒ½ (Function)**ï¼š
   - è¯†åˆ«è§†é¢‘æ¨å¹¿çš„æ ¸å¿ƒå–ç‚¹ï¼Œå¹¶æ˜ å°„åˆ°ä»¥ä¸‹æ ‡å‡†åˆ†ç±»è¯ï¼ˆè‹¥æ¶‰åŠå¤šä¸ªï¼Œä¼˜å…ˆé€‰æ‹©æœ€æ ¸å¿ƒçš„ä¸€ä¸ªï¼Œä»…åœ¨æ— æ³•åŒºåˆ†ä¸»æ¬¡æ—¶é€‰æ‹©â€œç»¼åˆå–ç‚¹â€ï¼‰ï¼š
   - åˆ†ç±»è¯åº“ï¼š[æœˆæš–æš–, é¥®é£Ÿå¥åº·å°åŠ©æ‰‹, å¥åº·å°ç›®æ ‡, å¿ƒç†å¥åº·è‡ªæµ‹, æµæ„Ÿå¥åº·æ”»ç•¥, è¯ç®¡å®¶, å¥åº·æ¡£æ¡ˆ, é—®ç­”, å£è…”å°åŠ©ç†, ä¸­åŒ»å…»ç”Ÿ, ç»¼åˆå–ç‚¹, AIè§£è¯»æ™ºèƒ½æŠ¥å‘Š]

3. **æ ¸å¿ƒç—›ç‚¹ (Pain Point)**ï¼š
   - ç»“åˆæ–‡æ¡ˆå’Œç”»é¢ï¼Œæ€»ç»“ç”¨æˆ·é¢ä¸´çš„å…·ä½“é—®é¢˜ã€‚
   - çº¦æŸï¼šå¿…é¡»ç¼©çŸ­æˆç®€å•çš„ä¸€å¥è¯ï¼ˆ15å­—ä»¥å†…ï¼‰ã€‚
   - ç¤ºä¾‹ï¼šâ€œå¿˜è®°è¯å“æ¥æºâ€ã€â€œä¸çŸ¥é“è¯å“ç¦å¿Œâ€ã€â€œå‡å°‘ç„¦è™‘â€ã€â€œç—›ç»ç¼“è§£â€ã€‚

4. **åº”ç”¨åœºæ™¯ (Scenario)**ï¼š
   - ä»…é™ä»ä»¥ä¸‹ä¸‰ä¸ªé€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š[ç”Ÿæ´»åœºæ™¯, å·¥ä½œåœºæ™¯, ç‰¹æ®Šåœºæ™¯]
   - è§„åˆ™ï¼šç‰¹æ®Šåœºæ™¯æƒé‡æœ€ä½ï¼Œä»…åœ¨æ— æ³•å½’ç±»ä¸ºç”Ÿæ´»æˆ–å·¥ä½œæ—¶ä½¿ç”¨ã€‚

5. **æ¦‚è¿° (Overview)**ï¼š
   - ç®€è¦æè¿°è§†é¢‘çš„ä¸»è¦å†…å®¹ã€å‰§æƒ…èµ°å‘æˆ–å±•ç°å½¢å¼ã€‚
   - **ä¸¥ç¦**ä½¿ç”¨â€œè§†é¢‘é€šè¿‡...â€ã€â€œè¯¥è§†é¢‘å±•ç¤ºäº†...â€ç­‰å¼•å¯¼è¯­ã€‚
   - ç›´æ¥é™ˆè¿°ç”»é¢å†…å®¹æˆ–å‰§æƒ…ã€‚

6. **æ·±åº¦åˆ†æ (Analysis)**ï¼š
   - ç»“åˆæä¾›çš„æŠ•æ”¾æ•°æ®ï¼ˆå±•ç°ã€ç‚¹å‡»ã€æ¶ˆè€—ã€æ¿€æ´»ã€ç‚¹å‡»ç‡CTRã€è½¬æ¢ç‡CVRï¼‰è¿›è¡Œç»¼åˆè¯„åˆ¤ã€‚
   - **ä¸¥ç¦**ä½¿ç”¨â€œæ ¹æ®æ•°æ®åˆ†æ...â€ã€â€œä»æ•°æ®æ¥çœ‹...â€ç­‰åºŸè¯ã€‚ç›´æ¥ç»™å‡ºç»“è®ºã€‚
   - **ç‰¹åˆ«æ³¨æ„**ï¼šè¯·æ˜¾è‘—æå‡ã€Œæ¶ˆè€—ã€æ•°æ®çš„åˆ†ææƒé‡ã€‚æ¶ˆè€—ä»£è¡¨äº†å…¬å¸çš„å®é™…æŠ•å…¥å’Œæ½œåœ¨æ”¶ç›Šè§„æ¨¡ã€‚
     - å¯¹äº**é«˜æ¶ˆè€—**è§†é¢‘ï¼šéœ€ä¸¥æ ¼å®¡è§†å…¶è½¬åŒ–ç‡å’Œç‚¹å‡»ç‡ï¼Œåˆ†æä¸ºä½•èƒ½è·‘å‡ºé«˜æ¶ˆè€—ï¼ˆç´ æå“ªé‡Œå¸å¼•äººï¼Ÿï¼‰ä»¥åŠæ˜¯å¦å­˜åœ¨â€œé«˜è€—ä½æ•ˆâ€çš„æµªè´¹é£é™©ã€‚
     - å¯¹äº**ä½æ¶ˆè€—**è§†é¢‘ï¼šåˆ†ææœªèƒ½è·‘é‡çš„åŸå› ï¼ˆæ˜¯å°é¢ä¸å¸å¼•äººå¯¼è‡´ç‚¹å‡»ç‡ä½ï¼Œè¿˜æ˜¯å†…å®¹å¹³åº¸ï¼‰ã€‚
   - ç»¼åˆåˆ¤æ–­è§†é¢‘çš„ä¼˜åŠ£ï¼Œå¹¶ç»™å‡ºä¼˜åŒ–æ–¹å‘ã€‚

**è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š
è¯·ç›´æ¥è¿”å›æ ‡å‡†çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«Markdownæ ‡è®°æˆ–å…¶ä»–åºŸè¯ï¼š
{
    "äººç¾¤": "å¹´è½»å¥³æ€§",
    "åŠŸèƒ½": "æœˆæš–æš–",
    "ç—›ç‚¹": "ç—›ç»ç¼“è§£",
    "åœºæ™¯": "ç”Ÿæ´»åœºæ™¯",
    "æ¦‚è¿°": "å¹´è½»å¥³æ€§åœ¨åŠå…¬å®¤æ‚ç€è‚šå­ï¼Œè¡¨æƒ…ç—›è‹¦ï¼Œéšåæ‹¿å‡ºæœˆæš–æš–äº§å“ä½¿ç”¨ï¼Œè¡¨æƒ…èˆ’ç¼“ã€‚",
    "åˆ†æ": "ç‚¹å‡»ç‡è¾ƒé«˜ï¼ˆX%ï¼‰ï¼Œå°é¢ç—›ç‚¹ç›´å‡»äººå¿ƒã€‚æ¶ˆè€—è¾ƒé«˜ä½†è½¬åŒ–ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–è½åœ°é¡µå¼•å¯¼ã€‚"
}"""

    def _call_qwen_vl(
        self, image_path: str, text_content: str, performance_data: Dict
    ) -> Optional[Dict]:
        """è°ƒç”¨ Qwen-VL-Plus APIã€‚"""
        url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        perf_str = "\n".join([f"{k}: {v}" for k, v in performance_data.items()])

        user_content = [
            {"image": f"data:image/jpeg;base64,{self._encode_image(image_path)}"},
            {
                "text": f"ã€è§†é¢‘æ–‡æ¡ˆã€‘ï¼š\n{text_content}\n\nã€æŠ•æ”¾æ•°æ®ã€‘ï¼š\n{perf_str}\n\nè¯·æ ¹æ®ä¸Šè¿°ç´ æå’Œæ•°æ®è¿›è¡Œåˆ†æã€‚"
            },
        ]

        payload = {
            "model": "qwen-vl-max",
            "input": {
                "messages": [
                    {
                        "role": "system",
                        "content": [{"text": self._get_system_prompt()}],
                    },
                    {"role": "user", "content": user_content},
                ]
            },
            "parameters": {"result_format": "message"},
        }

        for attempt in range(3):
            try:
                response = requests.post(url, headers=headers, json=payload, timeout=60)
                response.raise_for_status()
                result = response.json()

                if "output" in result and "choices" in result["output"]:
                    content = result["output"]["choices"][0]["message"]["content"][0][
                        "text"
                    ]
                    content = content.replace("```json", "").replace("```", "").strip()
                    return json.loads(content)
                else:
                    print(f"[API Error] æ„å¤–å“åº”: {result}")

            except Exception as e:
                print(f"[API Error] ç¬¬ {attempt + 1}/3 æ¬¡å°è¯•å¤±è´¥: {e}")
                time.sleep(2)

        return None

    def _find_assets(self, material_name: str) -> Tuple[Optional[str], Optional[str]]:
        """æŸ¥æ‰¾æŒ‡å®šç´ æåç§°çš„æ‹¼å›¾å’Œå­—å¹•æ–‡ä»¶ã€‚"""
        video_dir = self.assets_dir / material_name
        print(f"[Debug] æœç´¢ç›®å½•: {video_dir}")
        # å¤‡é€‰ï¼šé’ˆå¯¹å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å¤¹ï¼Ÿæœªå®ç°ï¼ŒåŸºäºåŸå§‹ä»£ç å‡è®¾å®Œå…¨åŒ¹é…

        if video_dir.exists():
            sheet_path = video_dir / "final_sheet.jpg"
            text_path = video_dir / "transcript_detailed.txt"

            if sheet_path.exists() and text_path.exists():
                return str(sheet_path), str(text_path)

        return None, None

    def _fetch_feishu_data(
        self, app_token: str = None, table_id: str = None
    ) -> List[Dict]:
        """è·å–å¹¶æ ‡å‡†åŒ–é£ä¹¦æ•°æ®ã€‚"""
        target_app_token = app_token
        target_table_id = table_id

        if not target_app_token:
            print("[Feishu] æ­£åœ¨ä» Wiki Token è§£æ App Token...")
            # target_app_token = self.feishu_client.get_app_token_from_wiki(config.WIKI_TOKEN)
            target_app_token = config.SOURCE_APP_TOKEN

        if not target_app_token:
            print("[Error] è·å– App Token å¤±è´¥")
            return []

        print(f"[Feishu] App Token: {target_app_token}")
        # å¦‚æœæœªæä¾› table_idï¼Œä½¿ç”¨é…ç½®æˆ–è·å–ç¬¬ä¸€ä¸ªè¡¨
        if not target_table_id:
            target_table_id = config.ANALYSIS_TABLE_ID

        records = self.feishu_client.get_all_records(
            target_app_token, target_table_id, config.ANALYSIS_VIEW_ID
        )

        normalized_data = []
        for r in records:
            fields = r.get("fields", {})

            # æ ‡å‡†åŒ–é“¾æ¥
            url_field = fields.get("è§†é¢‘é“¾æ¥")
            url = ""
            if isinstance(url_field, str):
                url = url_field
            elif isinstance(url_field, list) and len(url_field) > 0:
                url = url_field[0].get("url", "") or url_field[0].get("link", "")
            elif isinstance(url_field, dict):
                url = url_field.get("url", "") or url_field.get("link", "")

            # æ ‡å‡†åŒ–æ¥æº
            source_field = fields.get("æ¥æº", "")
            source = ""
            if isinstance(source_field, str):
                source = source_field
            elif isinstance(source_field, list) and len(source_field) > 0:
                item_0 = source_field[0]
                if isinstance(item_0, dict):
                    source = item_0.get("text", "") or item_0.get("name", "")
                else:
                    source = str(item_0)
            elif isinstance(source_field, dict):
                source = source_field.get("text", "") or source_field.get("name", "")

            item = {
                "ç´ æåç§°": fields.get("ç´ æåç§°", ""),
                "è§†é¢‘é“¾æ¥": url,
                "å±•ç°": fields.get("å±•ç°", 0),
                "ç‚¹å‡»": fields.get("ç‚¹å‡»", 0),
                "æ¶ˆè€—": fields.get("æ¶ˆè€—", 0),
                "æ¿€æ´»äººæ•°": fields.get("æ¿€æ´»äººæ•°", 0),
                "æ¥æº": source,
            }
            normalized_data.append(item)

        return normalized_data

    def process(
        self, app_token: str = None, table_id: str = None, progress_callback=None
    ) -> List[Dict]:
        """è¿è¡Œåˆ†æå¹¶è¿”å›ç»“æœ (ä¸ä¿å­˜åˆ° Excel)ã€‚"""
        data = self._fetch_feishu_data(app_token, table_id)

        results = []
        total_rows = len(data)
        print(f"å‘ç° {total_rows} è¡Œå¾…å¤„ç†æ•°æ®ã€‚")
        if progress_callback:
            progress_callback(f"ğŸ¤– å¼€å§‹ AI åˆ†æï¼Œå…± {total_rows} æ¡æ•°æ®...")

        for index, row in enumerate(data):
            material_name = str(row.get("ç´ æåç§°", ""))
            if material_name.lower().endswith(".mp4"):
                material_name = material_name[:-4]
            material_name = material_name.strip()

            if not material_name:
                continue

            print(f"\n[{index + 1}/{total_rows}] æ­£åœ¨å¤„ç†: {material_name}")

            sheet_path, text_path = self._find_assets(material_name)

            analysis_result = {}

            impressions = float(row.get("å±•ç°", 0) or 0)
            clicks = float(row.get("ç‚¹å‡»", 0) or 0)
            activations = float(row.get("æ¿€æ´»äººæ•°", 0) or 0)

            ctr = clicks / impressions if impressions > 0 else 0
            cvr = activations / clicks if clicks > 0 else 0

            if sheet_path and text_path:
                print("  å‘ç°æœ¬åœ°ç´ æã€‚æ­£åœ¨è°ƒç”¨ AI...")

                try:
                    with open(text_path, "r", encoding="utf-8") as f:
                        transcript = f.read()

                    perf_data = {
                        "å±•ç°": int(impressions),
                        "ç‚¹å‡»": int(clicks),
                        "æ¶ˆè€—": row.get("æ¶ˆè€—", 0),
                        "æ¿€æ´»äººæ•°": int(activations),
                        "ç‚¹å‡»ç‡": f"{ctr:.2%}",
                        "è½¬æ¢ç‡": f"{cvr:.2%}",
                    }

                    ai_res = self._call_qwen_vl(sheet_path, transcript, perf_data)
                    if ai_res:
                        analysis_result = ai_res
                        print("  AI åˆ†æå®Œæˆã€‚")
                    else:
                        print("  AI åˆ†æå¤±è´¥ã€‚")
                        if progress_callback:
                            progress_callback(
                                f"âŒ {material_name}: AI åˆ†æå¤±è´¥ (è¿”å›ç©º)"
                            )
                except Exception as e:
                    print(f"  AI åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    if progress_callback:
                        progress_callback(f"ğŸ’¥ {material_name}: AI åˆ†æå‡ºé”™: {e}")
            else:
                print("  è¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°ç´ æã€‚")
                if progress_callback:
                    progress_callback(f"âš ï¸ {material_name}: æœªæ‰¾åˆ°æœ¬åœ°ç´ æ (è·³è¿‡åˆ†æ)")
                analysis_result = {
                    "äººç¾¤": "æœªæ‰¾åˆ°ç´ æ",
                    "åŠŸèƒ½": "æœªæ‰¾åˆ°ç´ æ",
                    "åœºæ™¯": "æœªæ‰¾åˆ°ç´ æ",
                    "ç—›ç‚¹": "æœªæ‰¾åˆ°ç´ æ",
                    "æ¦‚è¿°": "æœªæ‰¾åˆ°ç´ æ",
                    "åˆ†æ": "æœªæ‰¾åˆ°ç´ æ",
                }

            row_data = {
                "ç´ æåç§°": material_name,
                "è§†é¢‘é“¾æ¥": row.get("è§†é¢‘é“¾æ¥", ""),
                "ç¼©ç•¥å›¾": sheet_path if sheet_path else "",
                "äººç¾¤": analysis_result.get("äººç¾¤", ""),
                "åŠŸèƒ½": analysis_result.get("åŠŸèƒ½", ""),
                "åœºæ™¯": analysis_result.get("åœºæ™¯", ""),
                "ç—›ç‚¹": analysis_result.get("ç—›ç‚¹", ""),
                "æ¦‚è¿°": analysis_result.get("æ¦‚è¿°", ""),
                "åˆ†æ": analysis_result.get("åˆ†æ", ""),
                "å±•ç°": int(impressions),
                "ç‚¹å‡»": int(clicks),
                "æ¶ˆè€—": row.get("æ¶ˆè€—", ""),
                "æ¿€æ´»äººæ•°": int(activations),
                "ç‚¹å‡»ç‡": ctr,
                "è½¬æ¢ç‡": cvr,
                "æ¥æº": row.get("æ¥æº", ""),
            }
            results.append(row_data)

            time.sleep(1)

        print(f"åˆ†æå®Œæˆã€‚ç”Ÿæˆäº† {len(results)} æ¡ç»“æœã€‚")
        if progress_callback:
            progress_callback(f"âœ… AI åˆ†æå…¨éƒ¨å®Œæˆï¼Œç”Ÿæˆ {len(results)} æ¡ç»“æœã€‚")

        return results

    # ä¿ç•™æ—§æ–¹æ³•ä»¥å…¼å®¹ CLI (å¦‚æœéœ€è¦)ï¼Œä½†åœ¨æ–°ç®¡çº¿ä¸­æœªä½¿ç”¨
    def _save_excel(self, results: List[Dict]):
        pass


def run_analyzer():
    print("ğŸš€ å¼€å§‹å¹¿å‘Šåˆ†æ...")
    analyzer = AdsAnalyzer()
    results = analyzer.process()

    syncer = FeishuSyncer()
    syncer.sync_data(results)


if __name__ == "__main__":
    run_analyzer()
